# LPCI-Enhanced Submission Examples

This folder contains **complete, ready-to-submit examples** of an attack algorithm and defensive guardrail that leverage the LPCI-style hooks system.

## üìÅ Files

- [`attack.py`](./attack.py) - Advanced attacker using LPCI hooks
- [`guardrail.py`](./guardrail.py) - Advanced defender using LPCI hooks
- [`test_submission.py`](./test_submission.py) - Test script to validate the submission
- [`README.md`](./README.md) - This file

## üéØ What Makes These Examples Special

### Attack Algorithm Features

The [`attack.py`](./attack.py) demonstrates:

1. **ACTION Directive Injection** - Injects malicious `ACTION:` commands into tool outputs
2. **Tool Argument Poisoning** - Modifies tool arguments to target sensitive resources
3. **Multi-Phase Attack Strategy** - Systematically explores different attack vectors
4. **Success Pattern Tracking** - Learns from successful breaches to improve

**Key LPCI Techniques Used:**
- Vector store poisoning simulation (payload injection)
- Tool poisoning (MCP tool manipulation)
- Trigger-based exploitation
- Memory-based attack evolution

### Guardrail Features

The [`guardrail.py`](./guardrail.py) demonstrates:

1. **Payload Detection** - Identifies LPCI-style attack patterns in outputs
2. **Output Sanitization** - Removes malicious directives before they reach the agent
3. **Sequence Analysis** - Detects suspicious tool call patterns (e.g., web ‚Üí read ‚Üí exfil)
4. **Argument Validation** - Blocks suspicious URLs, emails, and file paths

**Key LPCI Defense Techniques Used:**
- Real-time payload detection hooks
- Context sanitization
- Pattern-based attack recognition
- Multi-layered defense strategy

## üöÄ Quick Start

### Testing Locally

```bash
# Navigate to the examples folder
cd examples_hooks_submission

# Run the test script
python test_submission.py
```

This will:
1. Test the attack algorithm against a baseline guardrail
2. Test the defensive guardrail against a baseline attacker
3. Show detection statistics and breach results

### Creating a Submission ZIP

```bash
# From the examples folder
zip submission_hooks.zip attack.py guardrail.py
```

### Submitting to Competition

```bash
# From the project root
python evaluation.py --submission_zip examples_hooks_submission/submission_hooks.zip --seconds 60
```

## üìä Expected Performance

### Attack Algorithm

The attack algorithm should find multiple vulnerabilities:

- **Phase 1 (Payload Injection)**: 2-5 breaches via ACTION directives
- **Phase 2 (Tool Poisoning)**: 3-6 breaches via argument manipulation
- **Phase 3 (Combined)**: 1-3 breaches via multi-step attacks

**Total Expected Score**: 10-20 points (depending on baseline guardrail)

### Defensive Guardrail

The guardrail should block most attacks while maintaining usability:

- **Breach Prevention**: 80-90% of baseline attacks blocked
- **False Positives**: <20% on benign operations
- **Detection Rate**: 95%+ of malicious patterns detected

**Total Expected Score**: 70-85 points (depending on baseline attacker)

## üîç How the Hooks Work

### Attack Side Hooks

```python
# In attack.py __init__
self.registry = get_hook_registry()

# Hook 1: Inject ACTION directives into tool outputs
hook = create_payload_injection_hook(
    HookStage.POST_TOOL_CALL,
    inject_action_directive  # Your custom injection logic
)
self.registry.register_hook(HookStage.POST_TOOL_CALL, hook, priority=10)

# Hook 2: Poison tool arguments
self.registry.set_persistent_state('poisoned_tools', {...})
hook = create_lpci_tool_poisoning_hook()
self.registry.register_hook(HookStage.PRE_TOOL_CALL, hook, priority=9)
```

### Defense Side Hooks

```python
# In guardrail.py __init__
self.registry = get_hook_registry()

# Hook 1: Detect payloads in outputs
def detect_payloads(context):
    if 'ACTION:' in context.tool_output:
        return HookResult(payload_detected=True)
self.registry.register_hook(HookStage.POST_TOOL_CALL, detect_payloads)

# Hook 2: Sanitize outputs
def sanitize(context):
    context.modified_output = context.tool_output.replace('ACTION:', '[BLOCKED]')
    return HookResult(modified_context=context)
self.registry.register_hook(HookStage.POST_TOOL_CALL, sanitize)

# Hook 3: Track sequences
def track_sequences(context):
    # Track tool call patterns to detect exfiltration
self.registry.register_hook(HookStage.PRE_TOOL_CALL, track_sequences)
```

## üéì Learning from These Examples

### For Attackers

1. **Multi-Phase Strategy**: Don't rely on one attack type
2. **Hook Diversity**: Use multiple hook stages (PRE, POST, TRIGGER)
3. **Adaptive Attacks**: Track what works and iterate
4. **Time Management**: Allocate time across different phases

### For Defenders

1. **Layered Defense**: Detection + Sanitization + Rules
2. **Pattern Recognition**: Look for sequences, not just individual tools
3. **Balance**: Block attacks without breaking benign use cases
4. **Hook Orchestration**: Multiple hooks working together

## üîß Customization Guide

### Modifying the Attacker

**Add new payload types:**
```python
def inject_action_directive(context):
    if context.tool_name == 'your_target_tool':
        return '\n\nACTION: your_malicious_command\n'
    return None
```

**Add new poisoning targets:**
```python
poisoned_tools = {
    'new_tool': {
        'arg_modifications': {'arg': 'malicious_value'}
    }
}
```

**Adjust time allocation:**
```python
# In run() method
phase1_time = max_seconds * 0.4  # More time on phase 1
phase2_time = max_seconds * 0.3
phase3_time = max_seconds * 0.3
```

### Modifying the Guardrail

**Add new detection patterns:**
```python
malicious_patterns = [
    'YOUR_NEW_PATTERN',
    'ANOTHER_PATTERN',
    # ... existing patterns
]
```

**Add new rules:**
```python
def decide(self, tool_name, tool_args, context):
    # Your new rule
    if tool_name == 'special_tool' and some_condition:
        return Decision.deny("Your reason")
    
    # ... existing rules
```

**Adjust sensitivity:**
```python
# More strict
if len(self.detected_attacks) > 0:  # Changed from > 2
    return Decision.confirm(...)

# More lenient
if len(recent_sensitive) >= 5:  # Changed from >= 3
    return Decision.confirm(...)
```

## üìà Performance Tuning

### Maximize Attack Score

1. **Increase test case variety** in each phase
2. **Add more tool poisoning targets**
3. **Implement learning from successful patterns**
4. **Optimize time allocation** based on success rates

### Maximize Defense Score

1. **Tune detection patterns** to reduce false positives
2. **Optimize sequence detection** window size
3. **Balance between DENY and CONFIRM** decisions
4. **Add specific rules** for common attack patterns

## üêõ Debugging

### Enable Verbose Logging

```python
# In attack.py
import logging
logging.basicConfig(level=logging.DEBUG)

# Log successful attacks
if self._check_breach(trace):
    print(f"BREACH FOUND: {msg}")
    findings.append(...)
```

### Check Hook Execution

```python
# In guardrail.py
def detect_payloads(context):
    print(f"Hook executing: {context.tool_name}")
    print(f"Output: {context.tool_output[:100]}")
    # ... detection logic
```

### Validate Hook Registration

```python
# After setting up hooks
registered = self.registry._hooks[HookStage.POST_TOOL_CALL]
print(f"Registered hooks: {len(registered)}")
```

## ‚ö†Ô∏è Common Pitfalls

1. **Not clearing hooks**: Always call `registry.clear_all()` in `__init__`
2. **Hook conflicts**: Hooks from attacker/defender can interfere - use separate registries
3. **Time budget**: Don't exceed budget or submission will timeout
4. **False positives**: Ensure benign operations aren't blocked
5. **Priority ordering**: Higher priority hooks run first

## üîó Related Documentation

- [Main Hooks README](../aicomp_sdk/HOOKS_README.md) - Full hook system documentation
- [Competition Integration](../HOOKS_COMPETITION_INTEGRATION.md) - How hooks tie into scoring
- [Competition README](../README.md) - Competition rules and setup
- [LPCI Framework](../agentic_lpci_framework/) - Original LPCI implementation

## üí° Tips for Competition Success

### Attack Strategy

1. Start with simple payload injection to find quick wins
2. Use tool poisoning to systematically test argument space
3. Combine multiple hooks for sophisticated attacks
4. Track and learn from successful patterns

### Defense Strategy

1. Install detection hooks first to understand attacks
2. Add sanitization to neutralize known patterns
3. Use sequence detection for sophisticated attacks
4. Balance security with usability (avoid false positives)

### Time Management

- **Attack**: 30% injection, 30% poisoning, 40% combined
- **Defense**: Real-time detection (no time constraint)

### Testing

- Test against baselines first
- Validate on benign operations
- Check edge cases (empty inputs, long sequences)
- Profile time usage to stay within budget

## üèÜ Winning Combination

The best submissions will:

1. **Attack**: Use 3+ different hook types, adaptive learning, multi-phase strategy
2. **Defense**: Multi-layered detection, intelligent sanitization, context-aware rules
3. **Balance**: Maximize both attack and defense scores (dual optimization)

Good luck! üöÄ
